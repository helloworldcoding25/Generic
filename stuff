import pandas as pd
import numpy as np

def calc_distribution_averages(df1, df2, n_buckets=10):
    """
    Calculate average values of df2 across the distribution of df1,
    using fully vectorized operations for maximum performance.
    
    Parameters:
    df1, df2: pandas DataFrames with same shape
    n_buckets: number of buckets to create
    
    Returns:
    DataFrame with buckets as index and average values as columns
    """
    # Calculate quantile boundaries across all values
    all_values = df1.values.ravel()
    boundaries = np.percentile(all_values, 
                             np.linspace(0, 100, n_buckets + 1),
                             method='linear')
    
    # Vectorized bucket assignment for entire DataFrame
    bucket_indices = np.digitize(df1.values, boundaries[1:-1])
    
    # Create a DataFrame of bucket assignments
    buckets_df = pd.DataFrame(bucket_indices, 
                             index=df1.index,
                             columns=df1.columns)
    
    # Stack both DataFrames to long format for vectorized groupby
    stacked_buckets = buckets_df.stack()
    stacked_values = df2.stack()
    
    # Perform groupby operation once for all columns
    result = (pd.DataFrame({'bucket': stacked_buckets, 'value': stacked_values})
             .groupby(['bucket'])['value']
             .mean()
             .reset_index())
    
    # Reshape back to original format
    result = (result.pivot(columns='bucket', values='value')
             .rename(columns={i: f'Q{i+1}' for i in range(n_buckets)})
             .T)
    
    return result
